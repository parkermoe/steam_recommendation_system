{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5153209, 8), (59305, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_path = '/Volumes/DeepLearner/Search & Recommendation System/Data/australian_users_items_clean.json'\n",
    "review_path = '/Volumes/DeepLearner/Search & Recommendation System/Data/steam_reviews_clean.json'\n",
    "\n",
    "user_item_df = load_json_to_df(user_item_path)\n",
    "review_df = load_review_json_to_df(review_path)\n",
    "\n",
    "user_item_df.shape, review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>playtime_forever</th>\n",
       "      <th>playtime_2weeks</th>\n",
       "      <th>user_id</th>\n",
       "      <th>items_count</th>\n",
       "      <th>steam_id</th>\n",
       "      <th>user_url</th>\n",
       "      <th>funny</th>\n",
       "      <th>posted</th>\n",
       "      <th>last_edited</th>\n",
       "      <th>helpful</th>\n",
       "      <th>recommend</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22200</td>\n",
       "      <td>Zeno Clash</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>277</td>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>http://steamcommunity.com/profiles/76561197970...</td>\n",
       "      <td></td>\n",
       "      <td>Posted July 15, 2011.</td>\n",
       "      <td></td>\n",
       "      <td>No ratings yet</td>\n",
       "      <td>True</td>\n",
       "      <td>It's unique and worth a playthrough.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1250</td>\n",
       "      <td>Killing Floor</td>\n",
       "      <td>10006</td>\n",
       "      <td>0</td>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>277</td>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>http://steamcommunity.com/profiles/76561197970...</td>\n",
       "      <td></td>\n",
       "      <td>Posted November 5, 2011.</td>\n",
       "      <td></td>\n",
       "      <td>No ratings yet</td>\n",
       "      <td>True</td>\n",
       "      <td>Simple yet with great replayability. In my opi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43110</td>\n",
       "      <td>Metro 2033</td>\n",
       "      <td>834</td>\n",
       "      <td>0</td>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>277</td>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>http://steamcommunity.com/profiles/76561197970...</td>\n",
       "      <td></td>\n",
       "      <td>Posted April 21, 2011.</td>\n",
       "      <td></td>\n",
       "      <td>No ratings yet</td>\n",
       "      <td>True</td>\n",
       "      <td>Great atmosphere. The gunplay can be a bit chu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227300</td>\n",
       "      <td>Euro Truck Simulator 2</td>\n",
       "      <td>551</td>\n",
       "      <td>0</td>\n",
       "      <td>js41637</td>\n",
       "      <td>888</td>\n",
       "      <td>76561198035864385</td>\n",
       "      <td>http://steamcommunity.com/id/js41637</td>\n",
       "      <td></td>\n",
       "      <td>Posted September 8, 2013.</td>\n",
       "      <td></td>\n",
       "      <td>0 of 1 people (0%) found this review helpful</td>\n",
       "      <td>True</td>\n",
       "      <td>For a simple (it's actually not all that simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>239030</td>\n",
       "      <td>Papers, Please</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>js41637</td>\n",
       "      <td>888</td>\n",
       "      <td>76561198035864385</td>\n",
       "      <td>http://steamcommunity.com/id/js41637</td>\n",
       "      <td></td>\n",
       "      <td>Posted November 29, 2013.</td>\n",
       "      <td></td>\n",
       "      <td>1 of 4 people (25%) found this review helpful</td>\n",
       "      <td>True</td>\n",
       "      <td>Very fun little game to play when your bored o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_id               item_name  playtime_forever  playtime_2weeks  \\\n",
       "0   22200              Zeno Clash               271                0   \n",
       "1    1250           Killing Floor             10006                0   \n",
       "2   43110              Metro 2033               834                0   \n",
       "3  227300  Euro Truck Simulator 2               551                0   \n",
       "4  239030          Papers, Please               349                0   \n",
       "\n",
       "             user_id items_count           steam_id  \\\n",
       "0  76561197970982479         277  76561197970982479   \n",
       "1  76561197970982479         277  76561197970982479   \n",
       "2  76561197970982479         277  76561197970982479   \n",
       "3            js41637         888  76561198035864385   \n",
       "4            js41637         888  76561198035864385   \n",
       "\n",
       "                                            user_url funny  \\\n",
       "0  http://steamcommunity.com/profiles/76561197970...         \n",
       "1  http://steamcommunity.com/profiles/76561197970...         \n",
       "2  http://steamcommunity.com/profiles/76561197970...         \n",
       "3               http://steamcommunity.com/id/js41637         \n",
       "4               http://steamcommunity.com/id/js41637         \n",
       "\n",
       "                      posted last_edited  \\\n",
       "0      Posted July 15, 2011.               \n",
       "1   Posted November 5, 2011.               \n",
       "2     Posted April 21, 2011.               \n",
       "3  Posted September 8, 2013.               \n",
       "4  Posted November 29, 2013.               \n",
       "\n",
       "                                         helpful  recommend  \\\n",
       "0                                 No ratings yet       True   \n",
       "1                                 No ratings yet       True   \n",
       "2                                 No ratings yet       True   \n",
       "3   0 of 1 people (0%) found this review helpful       True   \n",
       "4  1 of 4 people (25%) found this review helpful       True   \n",
       "\n",
       "                                              review  \n",
       "0               It's unique and worth a playthrough.  \n",
       "1  Simple yet with great replayability. In my opi...  \n",
       "2  Great atmosphere. The gunplay can be a bit chu...  \n",
       "3  For a simple (it's actually not all that simpl...  \n",
       "4  Very fun little game to play when your bored o...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two datasets on 'user_id' and 'item_id'\n",
    "merged_df = pd.merge(user_item_df, review_df, how='inner', on=['user_id', 'item_id'])\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46317, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id             0\n",
       "item_name           0\n",
       "playtime_forever    0\n",
       "playtime_2weeks     0\n",
       "user_id             0\n",
       "items_count         0\n",
       "steam_id            0\n",
       "user_url            0\n",
       "funny               0\n",
       "posted              0\n",
       "last_edited         0\n",
       "helpful             0\n",
       "recommend           0\n",
       "review              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the merged DataFrame\n",
    "missing_values_merged = merged_df.isnull().sum()\n",
    "missing_values_merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "1. Converting text into TF-IDF vectors\n",
    "2. Normalizing playtime_forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46317, 5000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting to 5000 most frequent words for demonstration\n",
    "\n",
    "# Fit and transform the review text\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(merged_df['review']).toarray()\n",
    "\n",
    "# Display the shape to confirm the transformation\n",
    "tfidf_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46317, 1),\n",
       " array([[-0.40206923],\n",
       "        [ 0.04469064],\n",
       "        [-0.37623196],\n",
       "        [-0.38921944],\n",
       "        [-0.39848965]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the 'playtime_forever' feature\n",
    "playtime_scaled = scaler.fit_transform(merged_df[['playtime_forever']])\n",
    "\n",
    "# Display the shape and first few values to confirm the transformation\n",
    "playtime_scaled.shape, playtime_scaled[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32421, 5001), (6948, 5001), (6948, 5001), (32421,), (6948,), (6948,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine the features into a single array\n",
    "import numpy as np\n",
    "X_combined = np.hstack([tfidf_features, playtime_scaled])\n",
    "\n",
    "# Target variable: 'recommend' column\n",
    "y = merged_df['recommend'].values\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_combined, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the shape of each set to confirm the split\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SteamDataset(Dataset):\n",
    "    def __init__(self, X, y, user_ids, item_ids):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.user_ids = user_ids\n",
    "        self.item_ids = item_ids\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.user_ids[idx], self.item_ids[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1014, 218, 218)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "# Create arrays for user and item IDs corresponding to each row in the feature array\n",
    "user_ids_array = merged_df['user_id'].astype('category').cat.codes.values\n",
    "item_ids_array = merged_df['item_id'].astype('category').cat.codes.values\n",
    "\n",
    "# Split these arrays into training, validation, and test sets\n",
    "user_ids_train, user_ids_temp = train_test_split(user_ids_array, test_size=0.3, random_state=42)\n",
    "item_ids_train, item_ids_temp = train_test_split(item_ids_array, test_size=0.3, random_state=42)\n",
    "\n",
    "user_ids_val, user_ids_test = train_test_split(user_ids_temp, test_size=0.5, random_state=42)\n",
    "item_ids_val, item_ids_test = train_test_split(item_ids_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the shape of each set to confirm the split\n",
    "#user_ids_train.shape, user_ids_val.shape, user_ids_test.shape, item_ids_train.shape, item_ids_val.shape, item_ids_test.shape\n",
    "\n",
    "# Convert the numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.FloatTensor(y_val)\n",
    "\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "user_ids_train_tensor = torch.LongTensor(user_ids_train)\n",
    "item_ids_train_tensor = torch.LongTensor(item_ids_train)\n",
    "\n",
    "# Create a TensorDataset that includes user and item IDs\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor, user_ids_train_tensor, item_ids_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor, user_ids_val, item_ids_val)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor, user_ids_test, item_ids_test)\n",
    "\n",
    "# Create a TensorDataset from the tensors\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders for batching\n",
    "batch_size = 32  # You can change this value based on your system's capabilities\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Confirm the DataLoader setup\n",
    "len(train_loader), len(val_loader), len(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_text_features, num_numerical_features, num_users, num_items, embedding_dim):\n",
    "        super(HybridModel, self).__init__()\n",
    "        \n",
    "        # Text features\n",
    "        self.text_layer = nn.Linear(num_text_features, 128)\n",
    "        \n",
    "        # Numerical features\n",
    "        self.numerical_layer = nn.Linear(num_numerical_features, 64)\n",
    "        \n",
    "        # User and Item Embeddings\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # Dense layers\n",
    "        self.fc1 = nn.Linear(128 + 64 + 2 * embedding_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, text_data, numerical_data, user_id, item_id):\n",
    "        text_out = F.relu(self.text_layer(text_data))\n",
    "        num_out = F.relu(self.numerical_layer(numerical_data))\n",
    "        \n",
    "        user_embedded = self.user_embedding(user_id)\n",
    "        item_embedded = self.item_embedding(item_id)\n",
    "        \n",
    "        # Concatenating all the features\n",
    "        concatenated = torch.cat([text_out, num_out, user_embedded, item_embedded], dim=1)\n",
    "        \n",
    "        # Passing through dense layers\n",
    "        x = F.relu(self.fc1(concatenated))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Output layer\n",
    "        out = torch.sigmoid(self.output(x))\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Volumes/DeepLearner/Search & Recommendation System/Steam Recommendation System/steam_recommendation_system/data_pipeline.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/DeepLearner/Search%20%26%20Recommendation%20System/Steam%20Recommendation%20System/steam_recommendation_system/data_pipeline.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):  \u001b[39m# 10 epochs for demonstration\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/DeepLearner/Search%20%26%20Recommendation%20System/Steam%20Recommendation%20System/steam_recommendation_system/data_pipeline.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx, (X_batch, y_batch) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/DeepLearner/Search%20%26%20Recommendation%20System/Steam%20Recommendation%20System/steam_recommendation_system/data_pipeline.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/DeepLearner/Search%20%26%20Recommendation%20System/Steam%20Recommendation%20System/steam_recommendation_system/data_pipeline.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         outputs \u001b[39m=\u001b[39m model(text_data\u001b[39m=\u001b[39mX_batch[:, :\u001b[39m3950\u001b[39m], numerical_data\u001b[39m=\u001b[39mX_batch[:, \u001b[39m3950\u001b[39m:],\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Volumes/DeepLearner/Search%20%26%20Recommendation%20System/Steam%20Recommendation%20System/steam_recommendation_system/data_pipeline.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m                         user_id\u001b[39m=\u001b[39muser_ids, item_id\u001b[39m=\u001b[39mitem_ids)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/DeepLearner/Search%20%26%20Recommendation%20System/Steam%20Recommendation%20System/steam_recommendation_system/data_pipeline.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         loss \u001b[39m=\u001b[39m criterion(outputs, y_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Volumes/DeepLearner/Search%20%26%20Recommendation%20System/Steam%20Recommendation%20System/steam_recommendation_system/data_pipeline.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         \u001b[39m# Backward pass and optimization\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_ids' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = HybridModel(\n",
    "    num_text_features=3950,\n",
    "    num_numerical_features=1,\n",
    "    num_users=242,  # Total unique users\n",
    "    num_items=291,  # Total unique items\n",
    "    embedding_dim=50\n",
    ")\n",
    "\n",
    "# Calculate the number of unique users and items in the merged DataFrame\n",
    "total_unique_users = merged_df['user_id'].nunique()\n",
    "total_unique_items = merged_df['item_id'].nunique()\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):  # 10 epochs for demonstration\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(text_data=X_batch[:, :3950], numerical_data=X_batch[:, 3950:],\n",
    "                        user_id=user_ids, item_id=item_ids)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Print loss every epoch\n",
    "    print(f'Epoch [{epoch+1}/10], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
